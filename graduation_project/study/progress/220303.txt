-----미팅 내용-----
==논의완료
    1. 딥러닝 모델, CNN RNN(LSTM ATTENTION)? 
        RNN(LSTM ATTENTION)들은 이전 입력값에 영향을 받는 파일에 사용을 하는데, 음악의 경우 음성과 다르게 이전 입력값이 그다지 필요가 없다.
        CNN종류의 학습모델을 이용하자.  
    2. 자료형: 가공을 덜 한 Spectrogram을 주로 사용한다. 
        다만 piano임을 구분하기 위해 waveform도 동시에 사용할 수 있나는 다소 고민을 해보았다. 
    3. 가중치의 초깃값은, 피아노를 학습시킨 그것으로 하는게 좋을 것 같다. 
    4. 음악을 구하는 방법
        4.1.1: 우선은 동요등 만들기 쉬운것 위주로
        4.1.2: 과거 오케스트라등 실제 파일이 있고 저작권이 없는것들 
        4.1.3: 성과가 정말 좋다면 최신 가요 

==논의중, 문제점 
    1. 정답 label에서, 1박 vs 1/4박 x 4 를 어떻게 구분할 것인가? 
        1.1: 두개의 출력모델, 하나는 타건 타이밍, 하나는 음의높이를 구하는 출력 
            두개의 출력모델을 합친다면, 두 경우를 구분할 수 있다. 
            1.1.1: 타건 타이밍에서 음의 높이를 구할 것이냐, 혹은 타건 여부만 구할 것이냐 
                타건 여부만 구해도 괜찮을듯? 타건 시점의 특징적인 형태가 학습될 수 있다. 
                1.1.2와 연계하여, 타건 타이밍은 맞췄지만 음의 높이는 못 맞히는 경우가 생길수도 있긴 하다. 
                    그러나, 타건시에는 해당음이 상당히 크게 들리기 때문에 못 맞히는 경우는 없다고 보면 될 듯 하다. 
            1.1.2: 음의 높이를 구하는 것의 예상되는 문제점 
                피아노 악기의 음이 작다면, 그것을 과연 구할 수 있을 것인가? 
                    타건시의 음은 거의 확실히 구할 수 있을것으로 보임. 그렇다면, 음이 바뀌면 끝난것으로 간주. 
            1.1.3: 결국 정답레이블이 두 종류인 것인데, 독립적으로 학습하는가? 
                독립적으로 학습하는것이 옳바르다고 생각한다. 
    2. STFT의 길이는 가변인가 고정인가? 
        피아노마다 박자(빠르기)가 다르다. 그런데 STFT가 고정이면, STFT가 피아노의 음을 잘라먹는 현상이 생길 수 있다. 
        2.1: 어차피 피아노 박자로 잘라도, 사람의 연주오류, 의도적인 박자 비틀기로인해 잘라먹힐 수 있다.
            그러므로 STFT를 적절한 사이즈(충분히 작으면서 주파수 영역을 잘 표현할 수 있는 정도)로 한다. 
        2.2: 근데 어차피 피아노 박자를 구해야 악보로 표출이 가능하므로, 가변형으로 해도 괜찮을 것 같기도 하다. 
            2.2.1: 근데 피아노 박자는 항상 구할 수 있는게 맞나? 여러가지 섞인 음악의 경우에도 구해주는가? 
    3. 화음을 어떻게 구분할 것인가? 
        3.1: 정답 출력을 tuple 형태로 하여, 여러가지 음이 있으면 모두 포함하도록 한다. 
            이때의 정답으로 인정되는 확률은, 최대확률 대비 확률로 계산한다. (어느정도부터 인정하는지는 3.1.1)
                ex) 25% 10% 15% 50%의 확률은, 50%, 20% 30% 100%로 계산된다. 만약 인정 값이 40% 이상이라면, 두개의 음이 인정되는 것 
            3.1.1: 어느정도부터 인정할 것인지의 하이퍼파라미터, 혹은 수학적 계산 
            3.1.2: 손실함수를 어떻게 구할것인가? 
                직관적인 힌트/이해: 정답이 3개라면 각각 33% 33% 33%로 잡아서 손실함수를 계산한다? 
                    수학적인 계산을 해봐야 하지만 가능은 할 것 같다? 
                    3.1.1에서 수학적인 계산을 해보는 것이 필요할듯 
    4. 악기를 어떻게 구분할 것인가? 
        4.1: 악기를 구분하는 딥러닝 뜯어보기 
        4.2: 1.1.1에서 타건여부만 구하는 방법을 이용한다면, 피아노의 타건만 구분해서 할 수 있을듯 하다 .
    5. 128음계(미피음계) or 피아노음계(88) 모두 학습 
        5.1: 미피가 생각하기로는 피아노 음계를 벗어나는 것도 충분히 있으므로 128음계일 것이므로, 미피음계를 모두 학습할 수 있도록 하는것이 좋다.
            5.1.1: 128음계를 모두 나타내는법은, 같은 음악을 한 옥타브 올려버리는 방식등을 이용할 수 있다. 
                혹은, 아예 학습을 위해 다양한 음계를 넣어버린(실제 음악은 아닌것을) 학습시켜도 나쁘지 않을듯 하다.
    6. 사람은 어떻게 음악을 구분하는가? waveform 혹은 spectrogram에는 이를 구분할 수 있는 요소가 모두 있는것인가? 
        일단 기본적으로 사람이 구분하는것은 틀림없으니, 있긴 있다고 봐야한다. 
        1. 내 생각에는 waveform에는 반드시 있고, spectrogram에는 있을수도 있다는 것이다.
            waveform은 특수한 변형을 거치지 않았으므로 있다. 
            waveform STFT한 spectrogram의 경우, FT과정에서 손실되는게 있는지 더 공부가 필요하지만, 있을듯 하다. 
                왜냐하면, 음성인식등을 할 때 발음을 구분해야하는데, spectrogram이나 m-spectrogram, MFCC로도 음성인식을 하므로, 발음 구분이 된다는 것이다.
                이 발음이라는 것이 음의 높이가 같아도 다르게 들린다는 것인데, 다양한 악기라고 생각할 수 있지 않을까? 
        2. 내 생각에 사람이 구분하는 방법은, 타건시점 위주로 파악한다는 것이다.
            실제로 우리가 음악을 들을때는, 타건시점 위주로 인식한다고 생각한다. 
            또한 음의 지속의 경우, 실제로 음이 지속되어도 상대적으로 다른음에 비해 낮으면 인식일 거의 못한다고 봐야할듯 
            그렇다면, 전체 음량대비 상대적인 음량이 일정수준 이상이면, 사람이 그 음색패턴을 파악하여 구분할 수 있다는 생각이다.  
    7. 회귀를 적용할 수 있는 것인가? 한다면 어떻게 학습하고 어떻게 적용할까? 

==내가 추가로 생각한 문제점
    1. 다양한 악기가 혼재되어 있을경우, 1과 0으로 타건분류가 가능할 것인가? 
        학습 모델에 다양한 악기가 혼재되어 있다면, 충분히 분류할 수 있을듯 하다. 
        이때, 학습모델은 피아노와 동일한 시점에 타건한 것, 다른 시점에 타건한 것 모두 적절히 섞여 있어야 좋을듯 하다. 
    2. 음의 높이만을 구하는 모델을 사용할 수 있는가? 
        이것은 음량에 대한 정보가 없다. 즉 학습된 결과에 음량에 대한 정보가 없으므로, 타건시점을 알 수 없는 문제가 있다. 

==TO DO
    동요 wav파일을 이용해서, 간단하게 학습을 시도해본다. 
    모델: 
        wav -> spectrogram -> CNN -> 배열로 출력 (음표 위치-타격만, 음 지속 - 음만) 
        입력형태: wav 
        정답형태: 음 높이 + 1/32기준 박자, 쉼표는 X로 표현  
                정답 레이블은 STFT박자에 대한 정답이므로, 변환이 필요하다. 

-----추가적인 조사, 학습 내용 -----
==모델링 
    출력층을 두개의 레이어로 할 필요가 있나 싶다. 
        타건만 하는것, 피아노 음만 학습하는건 사실상 두개의 딥러닝이라고 봐도 될 듯 하다. 
    그냥 두개의 딥러닝을 수행하고, 출력을 합쳐서 결과를 만드는 것을 수행해보자. 
        딥러닝1: 타건시점만 맞추며, 1과 0으로 이루어짐. 
            1.타건 시점은 딱 1STFT만큼이냐, 혹은 좀 더 길게 할 것인가? 
                1STFT가 맞지만, 학습 용이도 등을 생각해보면 약간 더 길게 할 수 있을지도? 
            2.갑자기 RNN을 사용할 수도 있을것 같단 생각이 든다. 
                이전에는 피아노 영역대가 거의 비활성화 상태인데, 타건과 동시에 활성화 된다면, 보다 명확하게 타건을 구분할 수 있지 않을까? 
            근데 어차피 STFT한 것 전체를 학습해서 그 시점을 찾는 것이므로, 1.과 2.가 의미가 별로 없을지도? 즉 무의미한 고민일지도? 
        딥러닝2: 음만을 구하며, 여러 음이 포함될 수 있음에 유의 
            1. 문제3을 참고하여 설계하자.
            2. 피아노의 음이 가지는 배음형태를 발견했을때 그 음의 지속을 구할 수 있을지도. 
                2.1: 문제1의 경우, 1박과 1/4박 x 4 는 그래프의 형태가 다소 다를 것이다. 이를 어떻게 적용할 수 있는 방법이 없나? 
        출력label 설계 
            STFT와 피아노박자가 딱 떨어질 수는 없다. 잘라먹는 경우를 잘 생각하자. 
