1. CNN, RNN, LSTM, Attention 등 강의 찾아서 듣기 
    간단하게 구현 해볼수 있으면 해보기 
2. 데이터셋 만들기
    프로그램 알아보기: 스튜디오원, 케이크워크 
    악보 구하기: 
        저작권 X, 합주 악보, 
        피아노 기호?를 구현할수 있는 프로그램인가? 

음악을 생성하고 악기별로 spectrogram, m-spectrogram, MFCC를 한번 볼까? 
    배음관계나 파형등 어떤 차이가 생기는지 파악하는게 우선인 듯 하다. 

RNN, LSTM, Attention은 모두 이전 구간을 반영을 한다.
    악기에서 이전 구간을 반영할 필요가 있을까? 
        음의 잔향같은 것들은 모두 음이 생성된 이후에 생기는 것인데, 그걸 굳이 반영할 필요가 있을까 싶다.
            반영을 한다면 노래를 역으로 재생해서 반영할 수는 있을듯? 

window를 작게 만들면 최초로? 타격음이 형성되는 정도? 를 좀 알 수 있을듯? 
    그러고보면 spectrogram은 변수가 3개다. 흑백사진도 사실 변수는 3개임
        dimension(db), freq, time 

그 악기만의 특징 파형이 어떻게 구분될 수 있을까? 

CNN을 하면 인접 영역만 구분하는데, 악기의 배음을 포함할 수 있을까? 