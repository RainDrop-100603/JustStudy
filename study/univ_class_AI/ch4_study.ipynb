{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Deep Learning 구조 \n",
    "    * 학습모델 정의: optimizer = optim.SGD([W, b], lr=0.01)\n",
    "    * 딥러닝모델 정의: 직접 정의 [H = Wx + b], 모듈을 통한 정의 [nn.Linear(input size, output size)]\n",
    "        zeros를 통한 직접 정의는 w, b가 0으로 시작하는 반면, 모듈을 통한 정의는 랜덤?(아예랜덤은 아니고 나중에 배울듯)으로 시작한다.\n",
    "    * 손실함수 정의: MSE 직접 정의 torch.mean((H - y_train) ** 2), 모듈을 통한 정의 F.mse_loss(prediction, y_train)\n",
    "        * 직접적인 학습은 손실함수(cost)와 학습모델(optimizer)을 통해 학습된다. ?\n",
    "    * 반복횟수(epoch)를 정하고 반복학습 \n",
    "        * optimizer.zero_grad()  # 이전 grad값이 남아 있을 수 있으니 0초기화\n",
    "        * cost.backward()  # grad back propagation\n",
    "        * optimizer.step()  # learning from lr and grad\n",
    "\n",
    "* 함수 설명\n",
    "    * linear regression: 변수가 1개인 linear regression\n",
    "    * linear regression3: 변수가 3개인 linear regression, 변수가 3개여도 bias는 1개임을 유의 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression():\n",
    "    x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "    y_train = torch.FloatTensor([[5], [6], [7]])\n",
    "\n",
    "    W = torch.zeros(1, requires_grad=True)\n",
    "    b = torch.zeros(1, requires_grad=True)\n",
    "    optimizer = optim.SGD([W, b], lr=0.01)\n",
    "    # model = nn.Linear(1, 1)  # input, output\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    print(W)\n",
    "    # print(list(model.parameters())[0])\n",
    "\n",
    "    epochs = 3000\n",
    "    for epoch in range(epochs):\n",
    "        H = x_train * W + b\n",
    "        cost = torch.mean((H - y_train) ** 2)  # MSE 직접 구현\n",
    "        # prediction = model(x_train)\n",
    "        # cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        optimizer.zero_grad()  # 이전 grad값이 남아 있을 수 있으니 0초기화\n",
    "        cost.backward()  # grad back propagation\n",
    "        optimizer.step()  # learning from lr and grad\n",
    "\n",
    "        if (epoch + 1) % 300 == 0 or epoch == 0:\n",
    "            # W, b =list(model.parameters())[0], list(model.parameters())[1]\n",
    "            print(\n",
    "                \"Epoch {:4d}/{} W: {:.3f} b: {:.3f} Cost: {:.6f}\".format(\n",
    "                    (epoch + 1), epochs, W.item(), b.item(), cost.item()\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "linear_regression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression3():\n",
    "    x_train = torch.FloatTensor(\n",
    "        [[73, 80, 75], [93, 88, 93], [89, 91, 80], [96, 98, 100], [73, 66, 70]]\n",
    "    )\n",
    "    y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "    W = torch.zeros((3, 1), requires_grad=True)\n",
    "    b = torch.zeros(1, requires_grad=True)\n",
    "    optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "    # model = nn.Linear(3,1)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr = 1e-5)\n",
    "\n",
    "    print(W)\n",
    "    # print(list(model.parameters())[0])\n",
    "\n",
    "    epochs = 10000\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        prediction = x_train.matmul(W) + b\n",
    "        cost = torch.mean((prediction - y_train) ** 2)\n",
    "        # prediction = model(x_train)\n",
    "        # cost = F.mse_loss(prediction,y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 1000 == 0 or epoch == 1:\n",
    "            print(\n",
    "                \"Epoch: {:4d}/{}, Prediction: {} Cost: {:.6f}\".format(\n",
    "                    epoch, epochs, prediction.squeeze().detach(), cost.item()\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "linear_regression3()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce6f5f2176fa1015014ce62a292580aac2c44145c664deaa66f90a66e6ca1327"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('univ_class_AI-1i58k4F2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
