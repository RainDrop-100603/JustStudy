{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda avaliable\n",
      "cnn_256_001_30\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch:    1] cost = 1.93356335 validation_accuracy = 0.401521385\n",
      "[Epoch:    2] cost = 1.53720927 validation_accuracy = 0.474712163\n",
      "[Epoch:    3] cost = 1.36135423 validation_accuracy = 0.513774693\n",
      "[Epoch:    4] cost = 1.25458431 validation_accuracy = 0.536800981\n",
      "[Epoch:    5] cost = 1.18094087 validation_accuracy = 0.545230269\n",
      "[Epoch:    6] cost = 1.11965942 validation_accuracy = 0.554893076\n",
      "[Epoch:    7] cost = 1.06377602 validation_accuracy = 0.565583885\n",
      "[Epoch:    8] cost = 1.01191759 validation_accuracy = 0.581620097\n",
      "[Epoch:    9] cost = 0.9640131 validation_accuracy = 0.589432597\n",
      "[Epoch:   10] cost = 0.918674529 validation_accuracy = 0.595600307\n",
      "[Epoch:   11] cost = 0.876574397 validation_accuracy = 0.600328922\n",
      "[Epoch:   12] cost = 0.835867047 validation_accuracy = 0.603207231\n",
      "[Epoch:   13] cost = 0.796459794 validation_accuracy = 0.607524693\n",
      "[Epoch:   14] cost = 0.75885725 validation_accuracy = 0.610608578\n",
      "[Epoch:   15] cost = 0.723121881 validation_accuracy = 0.613075674\n",
      "[Epoch:   16] cost = 0.68911767 validation_accuracy = 0.615953922\n",
      "[Epoch:   17] cost = 0.656782925 validation_accuracy = 0.614925981\n",
      "[Epoch:   18] cost = 0.625864148 validation_accuracy = 0.617598712\n",
      "[Epoch:   19] cost = 0.596185684 validation_accuracy = 0.620476961\n",
      "[Epoch:   20] cost = 0.567602575 validation_accuracy = 0.619654596\n",
      "[Epoch:   21] cost = 0.540288925 validation_accuracy = 0.621916115\n",
      "[Epoch:   22] cost = 0.514755487 validation_accuracy = 0.620682597\n",
      "[Epoch:   23] cost = 0.491731822 validation_accuracy = 0.616981924\n",
      "[Epoch:   24] cost = 0.472252399 validation_accuracy = 0.612870097\n",
      "[Epoch:   25] cost = 0.460653484 validation_accuracy = 0.602384865\n",
      "[Epoch:   26] cost = 0.460836709 validation_accuracy = 0.586348712\n",
      "[Epoch:   27] cost = 0.467633784 validation_accuracy = 0.611430943\n",
      "[Epoch:   28] cost = 0.453394204 validation_accuracy = 0.590254962\n",
      "[Epoch:   29] cost = 0.446307302 validation_accuracy = 0.584292769\n",
      "[Epoch:   30] cost = 0.422288835 validation_accuracy = 0.606702328\n",
      "test_accuracy = 0.875300467\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 3 32 32 -> 32 16 16\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # 32 16 16 -> 64 8 8\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(8 * 8 * 64, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)  # 가중치 초기화 방식\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)  # flatten\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_model(device, train_loader, validation_loader, learning_rate, training_epochs, model_name):\n",
    "    # 모델 및 학습방법 정의\n",
    "    model = CNN().to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)  # softmax 포함되어 있음\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    total_batch = len(train_loader)\n",
    "    validation_len = len(validation_loader)\n",
    "    for epoch in range(training_epochs):\n",
    "        # 학습\n",
    "        avg_cost = 0\n",
    "        for X, Y in train_loader:  # 미니 배치 단위로 꺼내온다, X = 미니배치, Y = label\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            hypothesis = model(X)\n",
    "            cost = criterion(hypothesis, Y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_cost += cost / total_batch\n",
    "        # validation data 검증\n",
    "        with torch.no_grad():\n",
    "            avg_accuracy = 0\n",
    "            for x, y in validation_loader:\n",
    "                x_test = x.to(device)\n",
    "                y_test = y.to(device)\n",
    "                prediction = model(x_test)\n",
    "                correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "                avg_accuracy += correct_prediction.float().mean()\n",
    "            avg_accuracy = avg_accuracy / validation_len\n",
    "            print(f\"[Epoch: {epoch+1:>4}] cost = {avg_cost:>.9} validation_accuracy = {avg_accuracy:>.9}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./data/{model_name}.pt\")\n",
    "\n",
    "\n",
    "def run_model(device, test_loader, model_name):\n",
    "    model = CNN().to(device)\n",
    "    model.load_state_dict(torch.load(f\"./data/{model_name}.pt\"))\n",
    "    model.eval()\n",
    "    test_len = len(test_loader)\n",
    "    with torch.no_grad():\n",
    "        avg_accuracy = 0\n",
    "        for x, y in test_loader:\n",
    "            x_test = x.to(device)\n",
    "            y_test = y.to(device)\n",
    "            prediction = model(x_test)\n",
    "            correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "            avg_accuracy += correct_prediction.float().mean()\n",
    "        avg_accuracy = avg_accuracy / test_len\n",
    "        print(f\"test_accuracy = {avg_accuracy:>.9}\")\n",
    "\n",
    "\n",
    "def get_data(batch_size, num_workers):\n",
    "    # train, validation, test dataset\n",
    "    # classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "    # transform.Compose: data를 원하는 형태로 가공\n",
    "    # normalize: (value-mean)/std, 3ch(rgb)라 3개, 0~1을 -1~1로 바꿈, transforms.Normalize((mean1, mean2, mean3), (std1, std2, std3)),\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    # train and validation set\n",
    "    tmp_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_len = int(len(tmp_set)*0.9)\n",
    "    val_len = len(tmp_set)-train_len\n",
    "    train_set, validation_set = torch.utils.data.random_split(tmp_set,[train_len,val_len])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True\n",
    "    )\n",
    "    validation_loader = train_loader = torch.utils.data.DataLoader(\n",
    "        validation_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=True\n",
    "    )\n",
    "\n",
    "    # test set\n",
    "    test_set = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    test_loader = train_loader = torch.utils.data.DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_loader, validation_loader, test_loader\n",
    "\n",
    "\n",
    "def main():\n",
    "    # device setup\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.manual_seed(777)\n",
    "    if device == \"cuda\":\n",
    "        print(\"cuda avaliable\")\n",
    "        torch.cuda.manual_seed_all(777)\n",
    "\n",
    "    # hyper parameter\n",
    "    num_workers = 4  # cpu 사용량, 스레드의 절반 정도면 무난하다.\n",
    "    batch_size = 256\n",
    "    learning_rate = 0.001\n",
    "    training_epochs = 30\n",
    "    model_name = \"cnn_256_001_30\"\n",
    "\n",
    "    # run \n",
    "    print(model_name)\n",
    "    train_loader, validation_loader, test_loader = get_data(batch_size, num_workers)\n",
    "    train_model(device, train_loader, validation_loader, learning_rate, training_epochs, model_name)\n",
    "    run_model(device, test_loader, model_name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 멀티태스킹 오류 안나려면 이렇게 실행해야 한다\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda avaliable\n",
      "cnn_16_0001_30\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch:    1] cost = 1.94043493 validation_accuracy = 0.399839759\n",
      "[Epoch:    2] cost = 1.62733495 validation_accuracy = 0.452323735\n",
      "[Epoch:    3] cost = 1.48007774 validation_accuracy = 0.480368584\n",
      "[Epoch:    4] cost = 1.39336526 validation_accuracy = 0.502203524\n",
      "[Epoch:    5] cost = 1.32964492 validation_accuracy = 0.517828524\n",
      "[Epoch:    6] cost = 1.27959692 validation_accuracy = 0.530248404\n",
      "[Epoch:    7] cost = 1.23857164 validation_accuracy = 0.535056114\n",
      "[Epoch:    8] cost = 1.20333135 validation_accuracy = 0.541065693\n",
      "[Epoch:    9] cost = 1.17212951 validation_accuracy = 0.547475994\n",
      "[Epoch:   10] cost = 1.14355958 validation_accuracy = 0.555088162\n",
      "[Epoch:   11] cost = 1.11691427 validation_accuracy = 0.559094548\n",
      "[Epoch:   12] cost = 1.09162939 validation_accuracy = 0.562900662\n",
      "[Epoch:   13] cost = 1.06753898 validation_accuracy = 0.568309307\n",
      "[Epoch:   14] cost = 1.04439366 validation_accuracy = 0.570913494\n",
      "[Epoch:   15] cost = 1.02213395 validation_accuracy = 0.573517621\n",
      "[Epoch:   16] cost = 1.0005486 validation_accuracy = 0.578525662\n",
      "[Epoch:   17] cost = 0.979710937 validation_accuracy = 0.579527259\n",
      "[Epoch:   18] cost = 0.959548891 validation_accuracy = 0.579927921\n",
      "[Epoch:   19] cost = 0.939956665 validation_accuracy = 0.582932711\n",
      "[Epoch:   20] cost = 0.920967281 validation_accuracy = 0.588742018\n",
      "[Epoch:   21] cost = 0.902532935 validation_accuracy = 0.587940693\n",
      "[Epoch:   22] cost = 0.884516835 validation_accuracy = 0.59214747\n",
      "[Epoch:   23] cost = 0.866978109 validation_accuracy = 0.59375\n",
      "[Epoch:   24] cost = 0.8498016 validation_accuracy = 0.596354187\n",
      "[Epoch:   25] cost = 0.833040655 validation_accuracy = 0.597756445\n",
      "[Epoch:   26] cost = 0.81660223 validation_accuracy = 0.599759638\n",
      "[Epoch:   27] cost = 0.800423443 validation_accuracy = 0.600160241\n",
      "[Epoch:   28] cost = 0.784533739 validation_accuracy = 0.59995997\n",
      "[Epoch:   29] cost = 0.768857956 validation_accuracy = 0.600761235\n",
      "[Epoch:   30] cost = 0.753326714 validation_accuracy = 0.600961566\n",
      "test_accuracy = 0.762799978\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 3 32 32 -> 32 16 16\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # 32 16 16 -> 64 8 8\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(8 * 8 * 64, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)  # 가중치 초기화 방식\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)  # flatten\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_model(device, train_loader, validation_loader, learning_rate, training_epochs, model_name):\n",
    "    # 모델 및 학습방법 정의\n",
    "    model = CNN().to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)  # softmax 포함되어 있음\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    total_batch = len(train_loader)\n",
    "    validation_len = len(validation_loader)\n",
    "    for epoch in range(training_epochs):\n",
    "        # 학습\n",
    "        avg_cost = 0\n",
    "        for X, Y in train_loader:  # 미니 배치 단위로 꺼내온다, X = 미니배치, Y = label\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            hypothesis = model(X)\n",
    "            cost = criterion(hypothesis, Y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_cost += cost / total_batch\n",
    "        # validation data 검증\n",
    "        with torch.no_grad():\n",
    "            avg_accuracy = 0\n",
    "            for x, y in validation_loader:\n",
    "                x_test = x.to(device)\n",
    "                y_test = y.to(device)\n",
    "                prediction = model(x_test)\n",
    "                correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "                avg_accuracy += correct_prediction.float().mean()\n",
    "            avg_accuracy = avg_accuracy / validation_len\n",
    "            print(f\"[Epoch: {epoch+1:>4}] cost = {avg_cost:>.9} validation_accuracy = {avg_accuracy:>.9}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./data/{model_name}.pt\")\n",
    "\n",
    "\n",
    "def run_model(device, test_loader, model_name):\n",
    "    model = CNN().to(device)\n",
    "    model.load_state_dict(torch.load(f\"./data/{model_name}.pt\"))\n",
    "    model.eval()\n",
    "    test_len = len(test_loader)\n",
    "    with torch.no_grad():\n",
    "        avg_accuracy = 0\n",
    "        for x, y in test_loader:\n",
    "            x_test = x.to(device)\n",
    "            y_test = y.to(device)\n",
    "            prediction = model(x_test)\n",
    "            correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "            avg_accuracy += correct_prediction.float().mean()\n",
    "        avg_accuracy = avg_accuracy / test_len\n",
    "        print(f\"test_accuracy = {avg_accuracy:>.9}\")\n",
    "\n",
    "\n",
    "def get_data(batch_size, num_workers):\n",
    "    # train, validation, test dataset\n",
    "    # classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "    # transform.Compose: data를 원하는 형태로 가공\n",
    "    # normalize: (value-mean)/std, 3ch(rgb)라 3개, 0~1을 -1~1로 바꿈, transforms.Normalize((mean1, mean2, mean3), (std1, std2, std3)),\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    # train and validation set\n",
    "    tmp_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_len = int(len(tmp_set)*0.9)\n",
    "    val_len = len(tmp_set)-train_len\n",
    "    train_set, validation_set = torch.utils.data.random_split(tmp_set,[train_len,val_len])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True\n",
    "    )\n",
    "    validation_loader = train_loader = torch.utils.data.DataLoader(\n",
    "        validation_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=True\n",
    "    )\n",
    "\n",
    "    # test set\n",
    "    test_set = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    test_loader = train_loader = torch.utils.data.DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_loader, validation_loader, test_loader\n",
    "\n",
    "\n",
    "def main():\n",
    "    # device setup\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.manual_seed(777)\n",
    "    if device == \"cuda\":\n",
    "        print(\"cuda avaliable\")\n",
    "        torch.cuda.manual_seed_all(777)\n",
    "\n",
    "    # hyper parameter\n",
    "    num_workers = 4  # cpu 사용량, 스레드의 절반 정도면 무난하다.\n",
    "    batch_size = 16\n",
    "    learning_rate = 0.0001\n",
    "    training_epochs = 30\n",
    "    model_name = \"cnn_16_0001_30\"\n",
    "\n",
    "    # run \n",
    "    print(model_name)\n",
    "    train_loader, validation_loader, test_loader = get_data(batch_size, num_workers)\n",
    "    train_model(device, train_loader, validation_loader, learning_rate, training_epochs, model_name)\n",
    "    run_model(device, test_loader, model_name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 멀티태스킹 오류 안나려면 이렇게 실행해야 한다\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda avaliable\n",
      "cnn2_256_001_30\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch:    1] cost = 1.9608258 validation_accuracy = 0.387335539\n",
      "[Epoch:    2] cost = 1.56321871 validation_accuracy = 0.477796048\n",
      "[Epoch:    3] cost = 1.39663792 validation_accuracy = 0.497532904\n",
      "[Epoch:    4] cost = 1.29948747 validation_accuracy = 0.502672672\n",
      "[Epoch:    5] cost = 1.21195579 validation_accuracy = 0.530016422\n",
      "[Epoch:    6] cost = 1.1338861 validation_accuracy = 0.549547672\n",
      "[Epoch:    7] cost = 1.06580412 validation_accuracy = 0.5625\n",
      "[Epoch:    8] cost = 1.00681794 validation_accuracy = 0.576685846\n",
      "[Epoch:    9] cost = 0.959876776 validation_accuracy = 0.601151347\n",
      "[Epoch:   10] cost = 0.909274697 validation_accuracy = 0.615748346\n",
      "[Epoch:   11] cost = 0.848771036 validation_accuracy = 0.631990135\n",
      "[Epoch:   12] cost = 0.79173708 validation_accuracy = 0.632606924\n",
      "[Epoch:   13] cost = 0.738178134 validation_accuracy = 0.636101961\n",
      "[Epoch:   14] cost = 0.687303424 validation_accuracy = 0.637129962\n",
      "[Epoch:   15] cost = 0.640018225 validation_accuracy = 0.637746692\n",
      "[Epoch:   16] cost = 0.593686998 validation_accuracy = 0.638980269\n",
      "[Epoch:   17] cost = 0.551076531 validation_accuracy = 0.640008211\n",
      "[Epoch:   18] cost = 0.51531148 validation_accuracy = 0.639185846\n",
      "[Epoch:   19] cost = 0.497233212 validation_accuracy = 0.62890625\n",
      "[Epoch:   20] cost = 0.461820453 validation_accuracy = 0.625822365\n",
      "[Epoch:   21] cost = 0.435642451 validation_accuracy = 0.604235172\n",
      "[Epoch:   22] cost = 0.446527809 validation_accuracy = 0.621504962\n",
      "[Epoch:   23] cost = 0.454369158 validation_accuracy = 0.633018076\n",
      "[Epoch:   24] cost = 0.398617417 validation_accuracy = 0.633429289\n",
      "[Epoch:   25] cost = 0.343997061 validation_accuracy = 0.611225307\n",
      "[Epoch:   26] cost = 0.324272275 validation_accuracy = 0.620476961\n",
      "[Epoch:   27] cost = 0.323674768 validation_accuracy = 0.617393076\n",
      "[Epoch:   28] cost = 0.301772952 validation_accuracy = 0.631373346\n",
      "[Epoch:   29] cost = 0.264243186 validation_accuracy = 0.614925981\n",
      "[Epoch:   30] cost = 0.270910025 validation_accuracy = 0.598478615\n",
      "test_accuracy = 0.873798072\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class CNN2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        # 3 32 32 -> 32 16 16\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # 32 16 16 -> 64 8 8\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # 64 8 8 -> 128 4 4\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(4 * 4 * 128, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)  # 가중치 초기화 방식\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)  # flatten\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_model(device, train_loader, validation_loader, learning_rate, training_epochs, model_name):\n",
    "    # 모델 및 학습방법 정의\n",
    "    model = CNN2().to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)  # softmax 포함되어 있음\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    total_batch = len(train_loader)\n",
    "    validation_len = len(validation_loader)\n",
    "    for epoch in range(training_epochs):\n",
    "        # 학습\n",
    "        avg_cost = 0\n",
    "        for X, Y in train_loader:  # 미니 배치 단위로 꺼내온다, X = 미니배치, Y = label\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            hypothesis = model(X)\n",
    "            cost = criterion(hypothesis, Y)\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_cost += cost / total_batch\n",
    "        # validation data 검증\n",
    "        with torch.no_grad():\n",
    "            avg_accuracy = 0\n",
    "            for x, y in validation_loader:\n",
    "                x_test = x.to(device)\n",
    "                y_test = y.to(device)\n",
    "                prediction = model(x_test)\n",
    "                correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "                avg_accuracy += correct_prediction.float().mean()\n",
    "            avg_accuracy = avg_accuracy / validation_len\n",
    "            print(f\"[Epoch: {epoch+1:>4}] cost = {avg_cost:>.9} validation_accuracy = {avg_accuracy:>.9}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./data/{model_name}.pt\")\n",
    "\n",
    "\n",
    "def run_model(device, test_loader, model_name):\n",
    "    model = CNN2().to(device)\n",
    "    model.load_state_dict(torch.load(f\"./data/{model_name}.pt\"))\n",
    "    model.eval()\n",
    "    test_len = len(test_loader)\n",
    "    with torch.no_grad():\n",
    "        avg_accuracy = 0\n",
    "        for x, y in test_loader:\n",
    "            x_test = x.to(device)\n",
    "            y_test = y.to(device)\n",
    "            prediction = model(x_test)\n",
    "            correct_prediction = torch.argmax(prediction, 1) == y_test\n",
    "            avg_accuracy += correct_prediction.float().mean()\n",
    "        avg_accuracy = avg_accuracy / test_len\n",
    "        print(f\"test_accuracy = {avg_accuracy:>.9}\")\n",
    "\n",
    "\n",
    "def get_data(batch_size, num_workers):\n",
    "    # train, validation, test dataset\n",
    "    # classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "    # transform.Compose: data를 원하는 형태로 가공\n",
    "    # normalize: (value-mean)/std, 3ch(rgb)라 3개, 0~1을 -1~1로 바꿈, transforms.Normalize((mean1, mean2, mean3), (std1, std2, std3)),\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    # train and validation set\n",
    "    tmp_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_len = int(len(tmp_set)*0.9)\n",
    "    val_len = len(tmp_set)-train_len\n",
    "    train_set, validation_set = torch.utils.data.random_split(tmp_set,[train_len,val_len])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True\n",
    "    )\n",
    "    validation_loader = train_loader = torch.utils.data.DataLoader(\n",
    "        validation_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=True\n",
    "    )\n",
    "\n",
    "    # test set\n",
    "    test_set = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    test_loader = train_loader = torch.utils.data.DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_loader, validation_loader, test_loader\n",
    "\n",
    "\n",
    "def main():\n",
    "    # device setup\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.manual_seed(777)\n",
    "    if device == \"cuda\":\n",
    "        print(\"cuda avaliable\")\n",
    "        torch.cuda.manual_seed_all(777)\n",
    "\n",
    "    # hyper parameter\n",
    "    num_workers = 4  # cpu 사용량, 스레드의 절반 정도면 무난하다.\n",
    "    batch_size = 256\n",
    "    learning_rate = 0.001\n",
    "    training_epochs =30\n",
    "    model_name = \"cnn2_256_001_30\"\n",
    "\n",
    "    # run \n",
    "    print(model_name)\n",
    "    train_loader, validation_loader, test_loader = get_data(batch_size, num_workers)\n",
    "    train_model(device, train_loader, validation_loader, learning_rate, training_epochs, model_name)\n",
    "    run_model(device, test_loader, model_name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 멀티태스킹 오류 안나려면 이렇게 실행해야 한다\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc131b8b101b984a122f52f354029d76580063cc58defb9f8f6ecaae2f96e377"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
