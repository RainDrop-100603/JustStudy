---책에서의 표현---
뉴런 = 노드 

---ch2 perceptron---
perceptron: 입력을 받으면 가중치와 편향에 따라 출력을 반환하는 알고리즘 
단층 perceptron: 
    AND,NAND,OR을 구현할 수 있다. 
    선형 영역을 표현한다.(좌표평면으로 나타내면 직선을 기준으로 값이 나뉜다.)
    y = (w1*x1+wx*x2>θ), x = 입력, w = 가중치,  θ = 임계값
    y = (w1*x1+w2x2+b>0), b = -θ = 편향 (b는 입계값의 다른 표현이다.)
다층 perceptron: 
    XOR을 구현할 수 있다.
    비선형 영역을 표현한다.(좌표평면으로 나타내면 곡선을 기준으로 값이 나뉜다.)
    x XOR y = (x OR y) AND (x NAND y) 
이론상으론 다층퍼셉트론으로 컴퓨터를 구현할 수 있다. 즉 복잡한 함수들도 모두 구현할 수 있다. 

---ch3 신경망---
활성화함수(activation func): 입력의 처리결과에 따른 출력을 나타내는 함수 
    활성화함수 h(a), a = b + w1x1 + w2x2 
        step func: h(a) = 1(a>0), 0(a<=0)
        sigmoid func: h(a) = 1/(1+exp(-a))
        ReLU func: h(a) = a(a>0), 0(a<=0)
            Rectified Linear Unit, 최근에 주로 이용하는 활성화 함수다.

    신경망에서는 비선형 함수를 이용해야한다.(위의 활성화 함수는 모두 비선형)
        선형함수는 아무리 층을 깊게 해도, 은닉층이 없는 네트워크로도 같은 기능을 할 수 있다.
            ex): h(a) = c*a -> h(h(h(a))) = c^3 * a (선형함수) 

    일반적으로 단순 퍼셉트론은 단층 네트워크에서 활성화 함수로 계단 함수를 이용한 것을, 
        다층 퍼셉트론은 신경망(다층 네트워크로 구성되고 계단함수보다 매끄러운 활성화함수 이용)을 나타난다.

    은닉층의 활성화 함수와 출력층의 활성화 함수가 다를 수 있다.
        출력층에는 목적에 따라 다양한 활성화 함수를 이용한다. 추후 다시 설명 
            항등함수: 회귀(입력데이터에서 연속적인 수치를 예측하는 문제)
            소프트맥스함수: 분류(데이터가 어느 클래스에 속하는지를 분류하는 문제) 

신경망의 순전파(forward propagation) 계산 
    신경만의 각 층의 계산은, 행렬 곱을 이용하여 간단하계 계산할 수 있다. 
    행렬의 곱은 np.dot(arrA,arrB)로 구현한다. 

출력층:
    추가적인 활성화함수를 사용한다. 회귀에서는 항등함수를, 분류에서는 소프트맥스함수를 사용하는것이 일반적 
        항등함수
            y = x 
        소프트맥스함수 
            y = np.exp(x) / np.sum(np.exp(x))
                -> 지수함수계산으로 인한 오버플로우등의 오류가 발생할 수 있다. 
            개선: 
                y = c*np.exp(x) / c*np.sum(np.exp(x))
                    = np.exp(x+log(c)) / np.sum(np.exp(x+log(c)))
                    = np.exp(x+C) / np.sum(np.exp(x+C))
                즉, 어떠한 값을 더하거나 빼도 결과는 같다는 것이다.
                일반적으로, max(x)값을 빼준다. 즉 일반적으로 C = -max(x) 이다. 
            특징:
                출력값이 0 ~ 1 사이의 실수다.
                출력값의 합이 1이다. 
                -> 소프트맥수 함수의 출력을 "확률" 이라고 해석할 수 있다. 
            신경망으로 "분류"할때는 생략하기도 한다.  
                학습단계에서는 출력함수를 이용하고(연산을 해야하니), 
                    추론(실사용)단계에서는 출력함수를 생략하는것이 일반적 (어차피 제일 높은거 하나로 분류하면 되니까)
    분류에서의 출력층의 뉴런 수 = 분류하고 싶은 클래스의 개수 로 설정하는것이 일반적 

손글씨 숫자인식 
    이미지를 픽셀로 쪼개고, 각 픽셀은 0~255사이의 값을 취한다. 